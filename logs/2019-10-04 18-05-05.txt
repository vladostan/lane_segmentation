Date and time: 2019-10-04 18-05-05

LOG: True
AUG: True
USE CLASS WEIGHTS: True
NUM CLASSES: 3
RESIZE: True
INPUT SHAPE: (256, 640, 3)
BACKBONE: resnet18
RANDOM STATE: 28
BATCH SIZE: 16
TRAIN:VAL:TEST SPLIT = 0.8:0.2:0.0

DATASETS USED: ['2019-04-24', '2019-05-08', '2019-05-15', '2019-05-20', '2019-05-22']
TOTAL FILES COUNT: 2606

Images dtype: uint8
Labels dtype: uint8

Images shape: (256, 640, 3)
Labels shape: (256, 640)

Training files count: 2084
Validation files count: 522
Testing files count: 0


Loading model weights: 2019-10-04 13-50-27

Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
data (InputLayer)               (None, 256, 640, 3)  0                                            
__________________________________________________________________________________________________
bn_data (BatchNormalization)    (None, 256, 640, 3)  9           data[0][0]                       
__________________________________________________________________________________________________
zero_padding2d_1 (ZeroPadding2D (None, 262, 646, 3)  0           bn_data[0][0]                    
__________________________________________________________________________________________________
conv0 (Conv2D)                  (None, 128, 320, 64) 9408        zero_padding2d_1[0][0]           
__________________________________________________________________________________________________
bn0 (BatchNormalization)        (None, 128, 320, 64) 256         conv0[0][0]                      
__________________________________________________________________________________________________
relu0 (Activation)              (None, 128, 320, 64) 0           bn0[0][0]                        
__________________________________________________________________________________________________
zero_padding2d_2 (ZeroPadding2D (None, 130, 322, 64) 0           relu0[0][0]                      
__________________________________________________________________________________________________
pooling0 (MaxPooling2D)         (None, 64, 160, 64)  0           zero_padding2d_2[0][0]           
__________________________________________________________________________________________________
stage1_unit1_bn1 (BatchNormaliz (None, 64, 160, 64)  256         pooling0[0][0]                   
__________________________________________________________________________________________________
stage1_unit1_relu1 (Activation) (None, 64, 160, 64)  0           stage1_unit1_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_3 (ZeroPadding2D (None, 66, 162, 64)  0           stage1_unit1_relu1[0][0]         
__________________________________________________________________________________________________
stage1_unit1_conv1 (Conv2D)     (None, 64, 160, 64)  36864       zero_padding2d_3[0][0]           
__________________________________________________________________________________________________
stage1_unit1_bn2 (BatchNormaliz (None, 64, 160, 64)  256         stage1_unit1_conv1[0][0]         
__________________________________________________________________________________________________
stage1_unit1_relu2 (Activation) (None, 64, 160, 64)  0           stage1_unit1_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_4 (ZeroPadding2D (None, 66, 162, 64)  0           stage1_unit1_relu2[0][0]         
__________________________________________________________________________________________________
stage1_unit1_conv2 (Conv2D)     (None, 64, 160, 64)  36864       zero_padding2d_4[0][0]           
__________________________________________________________________________________________________
stage1_unit1_sc (Conv2D)        (None, 64, 160, 64)  4096        stage1_unit1_relu1[0][0]         
__________________________________________________________________________________________________
add_1 (Add)                     (None, 64, 160, 64)  0           stage1_unit1_conv2[0][0]         
                                                                 stage1_unit1_sc[0][0]            
__________________________________________________________________________________________________
stage1_unit2_bn1 (BatchNormaliz (None, 64, 160, 64)  256         add_1[0][0]                      
__________________________________________________________________________________________________
stage1_unit2_relu1 (Activation) (None, 64, 160, 64)  0           stage1_unit2_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_5 (ZeroPadding2D (None, 66, 162, 64)  0           stage1_unit2_relu1[0][0]         
__________________________________________________________________________________________________
stage1_unit2_conv1 (Conv2D)     (None, 64, 160, 64)  36864       zero_padding2d_5[0][0]           
__________________________________________________________________________________________________
stage1_unit2_bn2 (BatchNormaliz (None, 64, 160, 64)  256         stage1_unit2_conv1[0][0]         
__________________________________________________________________________________________________
stage1_unit2_relu2 (Activation) (None, 64, 160, 64)  0           stage1_unit2_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_6 (ZeroPadding2D (None, 66, 162, 64)  0           stage1_unit2_relu2[0][0]         
__________________________________________________________________________________________________
stage1_unit2_conv2 (Conv2D)     (None, 64, 160, 64)  36864       zero_padding2d_6[0][0]           
__________________________________________________________________________________________________
add_2 (Add)                     (None, 64, 160, 64)  0           stage1_unit2_conv2[0][0]         
                                                                 add_1[0][0]                      
__________________________________________________________________________________________________
stage2_unit1_bn1 (BatchNormaliz (None, 64, 160, 64)  256         add_2[0][0]                      
__________________________________________________________________________________________________
stage2_unit1_relu1 (Activation) (None, 64, 160, 64)  0           stage2_unit1_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_7 (ZeroPadding2D (None, 66, 162, 64)  0           stage2_unit1_relu1[0][0]         
__________________________________________________________________________________________________
stage2_unit1_conv1 (Conv2D)     (None, 32, 80, 128)  73728       zero_padding2d_7[0][0]           
__________________________________________________________________________________________________
stage2_unit1_bn2 (BatchNormaliz (None, 32, 80, 128)  512         stage2_unit1_conv1[0][0]         
__________________________________________________________________________________________________
stage2_unit1_relu2 (Activation) (None, 32, 80, 128)  0           stage2_unit1_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_8 (ZeroPadding2D (None, 34, 82, 128)  0           stage2_unit1_relu2[0][0]         
__________________________________________________________________________________________________
stage2_unit1_conv2 (Conv2D)     (None, 32, 80, 128)  147456      zero_padding2d_8[0][0]           
__________________________________________________________________________________________________
stage2_unit1_sc (Conv2D)        (None, 32, 80, 128)  8192        stage2_unit1_relu1[0][0]         
__________________________________________________________________________________________________
add_3 (Add)                     (None, 32, 80, 128)  0           stage2_unit1_conv2[0][0]         
                                                                 stage2_unit1_sc[0][0]            
__________________________________________________________________________________________________
stage2_unit2_bn1 (BatchNormaliz (None, 32, 80, 128)  512         add_3[0][0]                      
__________________________________________________________________________________________________
stage2_unit2_relu1 (Activation) (None, 32, 80, 128)  0           stage2_unit2_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_9 (ZeroPadding2D (None, 34, 82, 128)  0           stage2_unit2_relu1[0][0]         
__________________________________________________________________________________________________
stage2_unit2_conv1 (Conv2D)     (None, 32, 80, 128)  147456      zero_padding2d_9[0][0]           
__________________________________________________________________________________________________
stage2_unit2_bn2 (BatchNormaliz (None, 32, 80, 128)  512         stage2_unit2_conv1[0][0]         
__________________________________________________________________________________________________
stage2_unit2_relu2 (Activation) (None, 32, 80, 128)  0           stage2_unit2_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_10 (ZeroPadding2 (None, 34, 82, 128)  0           stage2_unit2_relu2[0][0]         
__________________________________________________________________________________________________
stage2_unit2_conv2 (Conv2D)     (None, 32, 80, 128)  147456      zero_padding2d_10[0][0]          
__________________________________________________________________________________________________
add_4 (Add)                     (None, 32, 80, 128)  0           stage2_unit2_conv2[0][0]         
                                                                 add_3[0][0]                      
__________________________________________________________________________________________________
stage3_unit1_bn1 (BatchNormaliz (None, 32, 80, 128)  512         add_4[0][0]                      
__________________________________________________________________________________________________
stage3_unit1_relu1 (Activation) (None, 32, 80, 128)  0           stage3_unit1_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_11 (ZeroPadding2 (None, 34, 82, 128)  0           stage3_unit1_relu1[0][0]         
__________________________________________________________________________________________________
stage3_unit1_conv1 (Conv2D)     (None, 16, 40, 256)  294912      zero_padding2d_11[0][0]          
__________________________________________________________________________________________________
stage3_unit1_bn2 (BatchNormaliz (None, 16, 40, 256)  1024        stage3_unit1_conv1[0][0]         
__________________________________________________________________________________________________
stage3_unit1_relu2 (Activation) (None, 16, 40, 256)  0           stage3_unit1_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_12 (ZeroPadding2 (None, 18, 42, 256)  0           stage3_unit1_relu2[0][0]         
__________________________________________________________________________________________________
stage3_unit1_conv2 (Conv2D)     (None, 16, 40, 256)  589824      zero_padding2d_12[0][0]          
__________________________________________________________________________________________________
stage3_unit1_sc (Conv2D)        (None, 16, 40, 256)  32768       stage3_unit1_relu1[0][0]         
__________________________________________________________________________________________________
add_5 (Add)                     (None, 16, 40, 256)  0           stage3_unit1_conv2[0][0]         
                                                                 stage3_unit1_sc[0][0]            
__________________________________________________________________________________________________
stage3_unit2_bn1 (BatchNormaliz (None, 16, 40, 256)  1024        add_5[0][0]                      
__________________________________________________________________________________________________
stage3_unit2_relu1 (Activation) (None, 16, 40, 256)  0           stage3_unit2_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_13 (ZeroPadding2 (None, 18, 42, 256)  0           stage3_unit2_relu1[0][0]         
__________________________________________________________________________________________________
stage3_unit2_conv1 (Conv2D)     (None, 16, 40, 256)  589824      zero_padding2d_13[0][0]          
__________________________________________________________________________________________________
stage3_unit2_bn2 (BatchNormaliz (None, 16, 40, 256)  1024        stage3_unit2_conv1[0][0]         
__________________________________________________________________________________________________
stage3_unit2_relu2 (Activation) (None, 16, 40, 256)  0           stage3_unit2_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_14 (ZeroPadding2 (None, 18, 42, 256)  0           stage3_unit2_relu2[0][0]         
__________________________________________________________________________________________________
stage3_unit2_conv2 (Conv2D)     (None, 16, 40, 256)  589824      zero_padding2d_14[0][0]          
__________________________________________________________________________________________________
add_6 (Add)                     (None, 16, 40, 256)  0           stage3_unit2_conv2[0][0]         
                                                                 add_5[0][0]                      
__________________________________________________________________________________________________
stage4_unit1_bn1 (BatchNormaliz (None, 16, 40, 256)  1024        add_6[0][0]                      
__________________________________________________________________________________________________
stage4_unit1_relu1 (Activation) (None, 16, 40, 256)  0           stage4_unit1_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_15 (ZeroPadding2 (None, 18, 42, 256)  0           stage4_unit1_relu1[0][0]         
__________________________________________________________________________________________________
stage4_unit1_conv1 (Conv2D)     (None, 8, 20, 512)   1179648     zero_padding2d_15[0][0]          
__________________________________________________________________________________________________
stage4_unit1_bn2 (BatchNormaliz (None, 8, 20, 512)   2048        stage4_unit1_conv1[0][0]         
__________________________________________________________________________________________________
stage4_unit1_relu2 (Activation) (None, 8, 20, 512)   0           stage4_unit1_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_16 (ZeroPadding2 (None, 10, 22, 512)  0           stage4_unit1_relu2[0][0]         
__________________________________________________________________________________________________
stage4_unit1_conv2 (Conv2D)     (None, 8, 20, 512)   2359296     zero_padding2d_16[0][0]          
__________________________________________________________________________________________________
stage4_unit1_sc (Conv2D)        (None, 8, 20, 512)   131072      stage4_unit1_relu1[0][0]         
__________________________________________________________________________________________________
add_7 (Add)                     (None, 8, 20, 512)   0           stage4_unit1_conv2[0][0]         
                                                                 stage4_unit1_sc[0][0]            
__________________________________________________________________________________________________
stage4_unit2_bn1 (BatchNormaliz (None, 8, 20, 512)   2048        add_7[0][0]                      
__________________________________________________________________________________________________
stage4_unit2_relu1 (Activation) (None, 8, 20, 512)   0           stage4_unit2_bn1[0][0]           
__________________________________________________________________________________________________
zero_padding2d_17 (ZeroPadding2 (None, 10, 22, 512)  0           stage4_unit2_relu1[0][0]         
__________________________________________________________________________________________________
stage4_unit2_conv1 (Conv2D)     (None, 8, 20, 512)   2359296     zero_padding2d_17[0][0]          
__________________________________________________________________________________________________
stage4_unit2_bn2 (BatchNormaliz (None, 8, 20, 512)   2048        stage4_unit2_conv1[0][0]         
__________________________________________________________________________________________________
stage4_unit2_relu2 (Activation) (None, 8, 20, 512)   0           stage4_unit2_bn2[0][0]           
__________________________________________________________________________________________________
zero_padding2d_18 (ZeroPadding2 (None, 10, 22, 512)  0           stage4_unit2_relu2[0][0]         
__________________________________________________________________________________________________
stage4_unit2_conv2 (Conv2D)     (None, 8, 20, 512)   2359296     zero_padding2d_18[0][0]          
__________________________________________________________________________________________________
add_8 (Add)                     (None, 8, 20, 512)   0           stage4_unit2_conv2[0][0]         
                                                                 add_7[0][0]                      
__________________________________________________________________________________________________
bn1 (BatchNormalization)        (None, 8, 20, 512)   2048        add_8[0][0]                      
__________________________________________________________________________________________________
relu1 (Activation)              (None, 8, 20, 512)   0           bn1[0][0]                        
__________________________________________________________________________________________________
decoder_stage0_conv1 (Conv2D)   (None, 8, 20, 128)   65536       relu1[0][0]                      
__________________________________________________________________________________________________
decoder_stage0_bn1 (BatchNormal (None, 8, 20, 128)   512         decoder_stage0_conv1[0][0]       
__________________________________________________________________________________________________
decoder_stage0_relu1 (Activatio (None, 8, 20, 128)   0           decoder_stage0_bn1[0][0]         
__________________________________________________________________________________________________
decoder_stage0_upsample2 (UpSam (None, 16, 40, 128)  0           decoder_stage0_relu1[0][0]       
__________________________________________________________________________________________________
decoder_stage0_conv2 (Conv2D)   (None, 16, 40, 128)  147456      decoder_stage0_upsample2[0][0]   
__________________________________________________________________________________________________
decoder_stage0_bn2 (BatchNormal (None, 16, 40, 128)  512         decoder_stage0_conv2[0][0]       
__________________________________________________________________________________________________
decoder_stage0_relu2 (Activatio (None, 16, 40, 128)  0           decoder_stage0_bn2[0][0]         
__________________________________________________________________________________________________
decoder_stage0_conv3 (Conv2D)   (None, 16, 40, 256)  32768       decoder_stage0_relu2[0][0]       
__________________________________________________________________________________________________
decoder_stage0_bn3 (BatchNormal (None, 16, 40, 256)  1024        decoder_stage0_conv3[0][0]       
__________________________________________________________________________________________________
decoder_stage0_relu3 (Activatio (None, 16, 40, 256)  0           decoder_stage0_bn3[0][0]         
__________________________________________________________________________________________________
add_9 (Add)                     (None, 16, 40, 256)  0           decoder_stage0_relu3[0][0]       
                                                                 stage4_unit1_relu1[0][0]         
__________________________________________________________________________________________________
decoder_stage1_conv1 (Conv2D)   (None, 16, 40, 64)   16384       add_9[0][0]                      
__________________________________________________________________________________________________
decoder_stage1_bn1 (BatchNormal (None, 16, 40, 64)   256         decoder_stage1_conv1[0][0]       
__________________________________________________________________________________________________
decoder_stage1_relu1 (Activatio (None, 16, 40, 64)   0           decoder_stage1_bn1[0][0]         
__________________________________________________________________________________________________
decoder_stage1_upsample2 (UpSam (None, 32, 80, 64)   0           decoder_stage1_relu1[0][0]       
__________________________________________________________________________________________________
decoder_stage1_conv2 (Conv2D)   (None, 32, 80, 64)   36864       decoder_stage1_upsample2[0][0]   
__________________________________________________________________________________________________
decoder_stage1_bn2 (BatchNormal (None, 32, 80, 64)   256         decoder_stage1_conv2[0][0]       
__________________________________________________________________________________________________
decoder_stage1_relu2 (Activatio (None, 32, 80, 64)   0           decoder_stage1_bn2[0][0]         
__________________________________________________________________________________________________
decoder_stage1_conv3 (Conv2D)   (None, 32, 80, 128)  8192        decoder_stage1_relu2[0][0]       
__________________________________________________________________________________________________
decoder_stage1_bn3 (BatchNormal (None, 32, 80, 128)  512         decoder_stage1_conv3[0][0]       
__________________________________________________________________________________________________
decoder_stage1_relu3 (Activatio (None, 32, 80, 128)  0           decoder_stage1_bn3[0][0]         
__________________________________________________________________________________________________
add_10 (Add)                    (None, 32, 80, 128)  0           decoder_stage1_relu3[0][0]       
                                                                 stage3_unit1_relu1[0][0]         
__________________________________________________________________________________________________
decoder_stage2_conv1 (Conv2D)   (None, 32, 80, 32)   4096        add_10[0][0]                     
__________________________________________________________________________________________________
decoder_stage2_bn1 (BatchNormal (None, 32, 80, 32)   128         decoder_stage2_conv1[0][0]       
__________________________________________________________________________________________________
decoder_stage2_relu1 (Activatio (None, 32, 80, 32)   0           decoder_stage2_bn1[0][0]         
__________________________________________________________________________________________________
decoder_stage2_upsample2 (UpSam (None, 64, 160, 32)  0           decoder_stage2_relu1[0][0]       
__________________________________________________________________________________________________
decoder_stage2_conv2 (Conv2D)   (None, 64, 160, 32)  9216        decoder_stage2_upsample2[0][0]   
__________________________________________________________________________________________________
decoder_stage2_bn2 (BatchNormal (None, 64, 160, 32)  128         decoder_stage2_conv2[0][0]       
__________________________________________________________________________________________________
decoder_stage2_relu2 (Activatio (None, 64, 160, 32)  0           decoder_stage2_bn2[0][0]         
__________________________________________________________________________________________________
decoder_stage2_conv3 (Conv2D)   (None, 64, 160, 64)  2048        decoder_stage2_relu2[0][0]       
__________________________________________________________________________________________________
decoder_stage2_bn3 (BatchNormal (None, 64, 160, 64)  256         decoder_stage2_conv3[0][0]       
__________________________________________________________________________________________________
decoder_stage2_relu3 (Activatio (None, 64, 160, 64)  0           decoder_stage2_bn3[0][0]         
__________________________________________________________________________________________________
add_11 (Add)                    (None, 64, 160, 64)  0           decoder_stage2_relu3[0][0]       
                                                                 stage2_unit1_relu1[0][0]         
__________________________________________________________________________________________________
decoder_stage3_conv1 (Conv2D)   (None, 64, 160, 16)  1024        add_11[0][0]                     
__________________________________________________________________________________________________
decoder_stage3_bn1 (BatchNormal (None, 64, 160, 16)  64          decoder_stage3_conv1[0][0]       
__________________________________________________________________________________________________
decoder_stage3_relu1 (Activatio (None, 64, 160, 16)  0           decoder_stage3_bn1[0][0]         
__________________________________________________________________________________________________
decoder_stage3_upsample2 (UpSam (None, 128, 320, 16) 0           decoder_stage3_relu1[0][0]       
__________________________________________________________________________________________________
decoder_stage3_conv2 (Conv2D)   (None, 128, 320, 16) 2304        decoder_stage3_upsample2[0][0]   
__________________________________________________________________________________________________
decoder_stage3_bn2 (BatchNormal (None, 128, 320, 16) 64          decoder_stage3_conv2[0][0]       
__________________________________________________________________________________________________
decoder_stage3_relu2 (Activatio (None, 128, 320, 16) 0           decoder_stage3_bn2[0][0]         
__________________________________________________________________________________________________
decoder_stage3_conv3 (Conv2D)   (None, 128, 320, 64) 1024        decoder_stage3_relu2[0][0]       
__________________________________________________________________________________________________
decoder_stage3_bn3 (BatchNormal (None, 128, 320, 64) 256         decoder_stage3_conv3[0][0]       
__________________________________________________________________________________________________
decoder_stage3_relu3 (Activatio (None, 128, 320, 64) 0           decoder_stage3_bn3[0][0]         
__________________________________________________________________________________________________
add_12 (Add)                    (None, 128, 320, 64) 0           decoder_stage3_relu3[0][0]       
                                                                 relu0[0][0]                      
__________________________________________________________________________________________________
decoder_stage4_conv1 (Conv2D)   (None, 128, 320, 16) 1024        add_12[0][0]                     
__________________________________________________________________________________________________
decoder_stage4_bn1 (BatchNormal (None, 128, 320, 16) 64          decoder_stage4_conv1[0][0]       
__________________________________________________________________________________________________
decoder_stage4_relu1 (Activatio (None, 128, 320, 16) 0           decoder_stage4_bn1[0][0]         
__________________________________________________________________________________________________
decoder_stage4_upsample2 (UpSam (None, 256, 640, 16) 0           decoder_stage4_relu1[0][0]       
__________________________________________________________________________________________________
decoder_stage4_conv2 (Conv2D)   (None, 256, 640, 16) 2304        decoder_stage4_upsample2[0][0]   
__________________________________________________________________________________________________
decoder_stage4_bn2 (BatchNormal (None, 256, 640, 16) 64          decoder_stage4_conv2[0][0]       
__________________________________________________________________________________________________
decoder_stage4_relu2 (Activatio (None, 256, 640, 16) 0           decoder_stage4_bn2[0][0]         
__________________________________________________________________________________________________
decoder_stage4_conv3 (Conv2D)   (None, 256, 640, 16) 256         decoder_stage4_relu2[0][0]       
__________________________________________________________________________________________________
decoder_stage4_bn3 (BatchNormal (None, 256, 640, 16) 64          decoder_stage4_conv3[0][0]       
__________________________________________________________________________________________________
decoder_stage4_relu3 (Activatio (None, 256, 640, 16) 0           decoder_stage4_bn3[0][0]         
__________________________________________________________________________________________________
final_conv (Conv2D)             (None, 256, 640, 3)  435         decoder_stage4_relu3[0][0]       
__________________________________________________________________________________________________
softmax (Activation)            (None, 256, 640, 3)  0           final_conv[0][0]                 
==================================================================================================
Total params: 11,521,980
Trainable params: 11,511,958
Non-trainable params: 10,022
__________________________________________________________________________________________________

Optimizer: <keras.optimizers.Adam object at 0x7f09dd496588>
Learning rate: 6.25e-06
Loss: [<function dice_coef_multiclass_loss at 0x7f09f1e0d378>]
Metrics: ['categorical_accuracy']

Callbacks used:
<keras.callbacks.ReduceLROnPlateau object at 0x7f09be57d080>
<keras.callbacks.EarlyStopping object at 0x7f09dd3d6a20>
<keras.callbacks.CSVLogger object at 0x7f09be65fe10>
<keras.callbacks.ModelCheckpoint object at 0x7f09be65f780>
Steps per epoch: 130
Validation steps: 16

Starting training...

Epoch 1/1000
 - 169s - loss: 0.0078 - categorical_accuracy: 0.9964 - val_loss: 0.0139 - val_categorical_accuracy: 0.9946

Epoch 00001: val_loss improved from inf to 0.01385, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 2/1000
 - 150s - loss: 0.0078 - categorical_accuracy: 0.9964 - val_loss: 0.0136 - val_categorical_accuracy: 0.9946

Epoch 00002: val_loss improved from 0.01385 to 0.01364, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 3/1000
 - 179s - loss: 0.0079 - categorical_accuracy: 0.9964 - val_loss: 0.0137 - val_categorical_accuracy: 0.9946

Epoch 00003: val_loss did not improve from 0.01364
Epoch 4/1000
 - 184s - loss: 0.0078 - categorical_accuracy: 0.9965 - val_loss: 0.0136 - val_categorical_accuracy: 0.9946

Epoch 00004: val_loss did not improve from 0.01364
Epoch 5/1000
 - 183s - loss: 0.0077 - categorical_accuracy: 0.9965 - val_loss: 0.0136 - val_categorical_accuracy: 0.9947

Epoch 00005: val_loss improved from 0.01364 to 0.01358, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 6/1000
 - 183s - loss: 0.0076 - categorical_accuracy: 0.9965 - val_loss: 0.0137 - val_categorical_accuracy: 0.9946

Epoch 00006: val_loss did not improve from 0.01358
Epoch 7/1000
 - 179s - loss: 0.0075 - categorical_accuracy: 0.9966 - val_loss: 0.0138 - val_categorical_accuracy: 0.9946

Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.

Epoch 00007: val_loss did not improve from 0.01358
Epoch 8/1000
 - 181s - loss: 0.0078 - categorical_accuracy: 0.9965 - val_loss: 0.0134 - val_categorical_accuracy: 0.9947

Epoch 00008: val_loss improved from 0.01358 to 0.01337, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 9/1000
 - 182s - loss: 0.0076 - categorical_accuracy: 0.9966 - val_loss: 0.0132 - val_categorical_accuracy: 0.9948

Epoch 00009: val_loss improved from 0.01337 to 0.01317, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 10/1000
 - 181s - loss: 0.0075 - categorical_accuracy: 0.9966 - val_loss: 0.0131 - val_categorical_accuracy: 0.9949

Epoch 00010: val_loss improved from 0.01317 to 0.01312, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 11/1000
 - 178s - loss: 0.0074 - categorical_accuracy: 0.9966 - val_loss: 0.0132 - val_categorical_accuracy: 0.9948

Epoch 00011: val_loss did not improve from 0.01312
Epoch 12/1000
 - 185s - loss: 0.0075 - categorical_accuracy: 0.9966 - val_loss: 0.0130 - val_categorical_accuracy: 0.9949

Epoch 00012: val_loss improved from 0.01312 to 0.01298, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 13/1000
 - 151s - loss: 0.0074 - categorical_accuracy: 0.9967 - val_loss: 0.0128 - val_categorical_accuracy: 0.9950

Epoch 00013: val_loss improved from 0.01298 to 0.01284, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 14/1000
 - 183s - loss: 0.0073 - categorical_accuracy: 0.9967 - val_loss: 0.0129 - val_categorical_accuracy: 0.9950

Epoch 00014: val_loss did not improve from 0.01284
Epoch 15/1000
 - 185s - loss: 0.0073 - categorical_accuracy: 0.9967 - val_loss: 0.0129 - val_categorical_accuracy: 0.9950

Epoch 00015: val_loss did not improve from 0.01284
Epoch 16/1000
 - 187s - loss: 0.0073 - categorical_accuracy: 0.9967 - val_loss: 0.0131 - val_categorical_accuracy: 0.9949

Epoch 00016: val_loss did not improve from 0.01284
Epoch 17/1000
 - 181s - loss: 0.0072 - categorical_accuracy: 0.9967 - val_loss: 0.0130 - val_categorical_accuracy: 0.9949

Epoch 00017: val_loss did not improve from 0.01284
Epoch 18/1000
 - 182s - loss: 0.0072 - categorical_accuracy: 0.9967 - val_loss: 0.0130 - val_categorical_accuracy: 0.9949

Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.

Epoch 00018: val_loss did not improve from 0.01284
Epoch 19/1000
 - 182s - loss: 0.0072 - categorical_accuracy: 0.9967 - val_loss: 0.0130 - val_categorical_accuracy: 0.9949

Epoch 00019: val_loss did not improve from 0.01284
Epoch 20/1000
 - 182s - loss: 0.0072 - categorical_accuracy: 0.9967 - val_loss: 0.0129 - val_categorical_accuracy: 0.9950

Epoch 00020: val_loss did not improve from 0.01284
Epoch 21/1000
 - 183s - loss: 0.0071 - categorical_accuracy: 0.9967 - val_loss: 0.0127 - val_categorical_accuracy: 0.9950

Epoch 00021: val_loss improved from 0.01284 to 0.01274, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 22/1000
 - 181s - loss: 0.0071 - categorical_accuracy: 0.9968 - val_loss: 0.0126 - val_categorical_accuracy: 0.9951

Epoch 00022: val_loss improved from 0.01274 to 0.01257, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 23/1000
 - 183s - loss: 0.0070 - categorical_accuracy: 0.9968 - val_loss: 0.0126 - val_categorical_accuracy: 0.9951

Epoch 00023: val_loss did not improve from 0.01257
Epoch 24/1000
 - 181s - loss: 0.0070 - categorical_accuracy: 0.9968 - val_loss: 0.0126 - val_categorical_accuracy: 0.9951

Epoch 00024: val_loss did not improve from 0.01257
Epoch 25/1000
 - 180s - loss: 0.0070 - categorical_accuracy: 0.9968 - val_loss: 0.0126 - val_categorical_accuracy: 0.9951

Epoch 00025: val_loss did not improve from 0.01257
Epoch 26/1000
 - 188s - loss: 0.0070 - categorical_accuracy: 0.9968 - val_loss: 0.0124 - val_categorical_accuracy: 0.9952

Epoch 00026: val_loss improved from 0.01257 to 0.01241, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 27/1000
 - 182s - loss: 0.0070 - categorical_accuracy: 0.9968 - val_loss: 0.0125 - val_categorical_accuracy: 0.9951

Epoch 00027: val_loss did not improve from 0.01241
Epoch 28/1000
 - 184s - loss: 0.0070 - categorical_accuracy: 0.9968 - val_loss: 0.0125 - val_categorical_accuracy: 0.9952

Epoch 00028: val_loss did not improve from 0.01241
Epoch 29/1000
 - 187s - loss: 0.0069 - categorical_accuracy: 0.9968 - val_loss: 0.0126 - val_categorical_accuracy: 0.9951

Epoch 00029: val_loss did not improve from 0.01241
Epoch 30/1000
 - 184s - loss: 0.0069 - categorical_accuracy: 0.9969 - val_loss: 0.0123 - val_categorical_accuracy: 0.9952

Epoch 00030: val_loss improved from 0.01241 to 0.01231, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 31/1000
 - 184s - loss: 0.0069 - categorical_accuracy: 0.9968 - val_loss: 0.0124 - val_categorical_accuracy: 0.9952

Epoch 00031: val_loss did not improve from 0.01231
Epoch 32/1000
 - 185s - loss: 0.0069 - categorical_accuracy: 0.9968 - val_loss: 0.0124 - val_categorical_accuracy: 0.9952

Epoch 00032: val_loss did not improve from 0.01231
Epoch 33/1000
 - 188s - loss: 0.0069 - categorical_accuracy: 0.9968 - val_loss: 0.0124 - val_categorical_accuracy: 0.9952

Epoch 00033: val_loss did not improve from 0.01231
Epoch 34/1000
 - 187s - loss: 0.0069 - categorical_accuracy: 0.9969 - val_loss: 0.0123 - val_categorical_accuracy: 0.9952

Epoch 00034: val_loss improved from 0.01231 to 0.01227, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 35/1000
 - 183s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0123 - val_categorical_accuracy: 0.9952

Epoch 00035: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.

Epoch 00035: val_loss improved from 0.01227 to 0.01226, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 36/1000
 - 188s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0123 - val_categorical_accuracy: 0.9952

Epoch 00036: val_loss did not improve from 0.01226
Epoch 37/1000
 - 266s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0123 - val_categorical_accuracy: 0.9952

Epoch 00037: val_loss did not improve from 0.01226
Epoch 38/1000
 - 428s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9952

Epoch 00038: val_loss improved from 0.01226 to 0.01220, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 39/1000
 - 220s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9953

Epoch 00039: val_loss improved from 0.01220 to 0.01220, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 40/1000
 - 220s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9953

Epoch 00040: val_loss did not improve from 0.01220
Epoch 41/1000
 - 223s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9952

Epoch 00041: val_loss did not improve from 0.01220
Epoch 42/1000
 - 221s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9953

Epoch 00042: val_loss improved from 0.01220 to 0.01216, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 43/1000
 - 217s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9953

Epoch 00043: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.

Epoch 00043: val_loss did not improve from 0.01216
Epoch 44/1000
 - 223s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00044: val_loss improved from 0.01216 to 0.01215, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 45/1000
 - 245s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9953

Epoch 00045: val_loss did not improve from 0.01215
Epoch 46/1000
 - 229s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00046: val_loss improved from 0.01215 to 0.01210, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 47/1000
 - 227s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00047: val_loss did not improve from 0.01210
Epoch 48/1000
 - 240s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0122 - val_categorical_accuracy: 0.9953

Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.

Epoch 00048: val_loss did not improve from 0.01210
Epoch 49/1000
 - 232s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00049: val_loss did not improve from 0.01210
Epoch 50/1000
 - 245s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00050: val_loss improved from 0.01210 to 0.01210, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 51/1000
 - 241s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00051: val_loss did not improve from 0.01210
Epoch 52/1000
 - 244s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00052: val_loss did not improve from 0.01210
Epoch 53/1000
 - 242s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00053: val_loss improved from 0.01210 to 0.01208, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 54/1000
 - 251s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00054: val_loss improved from 0.01208 to 0.01206, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 55/1000
 - 249s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.

Epoch 00055: val_loss did not improve from 0.01206
Epoch 56/1000
 - 239s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00056: val_loss did not improve from 0.01206
Epoch 57/1000
 - 247s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00057: val_loss did not improve from 0.01206
Epoch 58/1000
 - 245s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00058: val_loss improved from 0.01206 to 0.01206, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 59/1000
 - 255s - loss: 0.0066 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00059: val_loss improved from 0.01206 to 0.01205, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 60/1000
 - 271s - loss: 0.0066 - categorical_accuracy: 0.9970 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00060: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.

Epoch 00060: val_loss improved from 0.01205 to 0.01203, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 61/1000
 - 258s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00061: val_loss did not improve from 0.01203
Epoch 62/1000
 - 253s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00062: val_loss improved from 0.01203 to 0.01198, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 63/1000
 - 269s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0121 - val_categorical_accuracy: 0.9953

Epoch 00063: val_loss did not improve from 0.01198
Epoch 64/1000
 - 265s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00064: val_loss did not improve from 0.01198
Epoch 65/1000
 - 272s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0119 - val_categorical_accuracy: 0.9954

Epoch 00065: val_loss improved from 0.01198 to 0.01185, saving model to weights/2019-10-04 18-05-05.hdf5
Epoch 66/1000
 - 275s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00066: val_loss did not improve from 0.01185
Epoch 67/1000
 - 262s - loss: 0.0066 - categorical_accuracy: 0.9970 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00067: val_loss did not improve from 0.01185
Epoch 68/1000
 - 229s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00068: val_loss did not improve from 0.01185
Epoch 69/1000
 - 228s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00069: val_loss did not improve from 0.01185
Epoch 70/1000
 - 227s - loss: 0.0066 - categorical_accuracy: 0.9970 - val_loss: 0.0119 - val_categorical_accuracy: 0.9954

Epoch 00070: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.

Epoch 00070: val_loss did not improve from 0.01185
Epoch 71/1000
 - 230s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00071: val_loss did not improve from 0.01185
Epoch 72/1000
 - 230s - loss: 0.0068 - categorical_accuracy: 0.9969 - val_loss: 0.0120 - val_categorical_accuracy: 0.9953

Epoch 00072: val_loss did not improve from 0.01185
Epoch 73/1000
 - 251s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0119 - val_categorical_accuracy: 0.9954

Epoch 00073: val_loss did not improve from 0.01185
Epoch 74/1000
 - 239s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0119 - val_categorical_accuracy: 0.9954

Epoch 00074: val_loss did not improve from 0.01185
Epoch 75/1000
 - 239s - loss: 0.0067 - categorical_accuracy: 0.9969 - val_loss: 0.0119 - val_categorical_accuracy: 0.9954

Epoch 00075: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.

Epoch 00075: val_loss did not improve from 0.01185
Epoch 00075: early stopping
Finished training

Date and time: 2019-10-04 22-34-49

