Date and time: 2019-01-14 08-12-32

Datasets used: ['/home/v.ostankovich/lanes-segmentation/data/images/innopolis']

633
633
Image dtype:uint8
Label dtype:uint8

633
633
0
0
Class weights: [0.16541089 1.         1.42351978]

Model summary:
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 640, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 640, 64) 1792        input_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 640, 64) 36928       conv2d_1[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 320, 64) 0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 320, 128 73856       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 320, 128 147584      conv2d_3[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 160, 128) 0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 64, 160, 256) 295168      max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 160, 256) 590080      conv2d_5[0][0]                   
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 80, 256)  0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 80, 512)  1180160     max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 80, 512)  2359808     conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 32, 80, 512)  0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
up_sampling2d_1 (UpSampling2D)  (None, 64, 160, 512) 0           dropout_1[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 64, 160, 256) 524544      up_sampling2d_1[0][0]            
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 64, 160, 512) 0           conv2d_6[0][0]                   
                                                                 conv2d_9[0][0]                   
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 64, 160, 256) 1179904     concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 64, 160, 256) 590080      conv2d_10[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_2 (UpSampling2D)  (None, 128, 320, 256 0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 128, 320, 128 131200      up_sampling2d_2[0][0]            
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 128, 320, 256 0           conv2d_4[0][0]                   
                                                                 conv2d_12[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 128, 320, 128 295040      concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 128, 320, 128 147584      conv2d_13[0][0]                  
__________________________________________________________________________________________________
up_sampling2d_3 (UpSampling2D)  (None, 256, 640, 128 0           conv2d_14[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 256, 640, 64) 32832       up_sampling2d_3[0][0]            
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 256, 640, 128 0           conv2d_2[0][0]                   
                                                                 conv2d_15[0][0]                  
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 256, 640, 64) 73792       concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 640, 64) 36928       conv2d_16[0][0]                  
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 640, 3)  195         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 256, 640, 3)  0           conv2d_18[0][0]                  
==================================================================================================
Total params: 7,697,475
Trainable params: 7,697,475
Non-trainable params: 0
__________________________________________________________________________________________________
Optimizer: <keras.optimizers.Adam object at 0x7f149f850850>, learning rate: 0.0001, loss: categorical_crossentropy, metrics: ['accuracy']

Callbacks: [<keras.callbacks.ModelCheckpoint object at 0x7f149f850a50>, <keras.callbacks.ReduceLROnPlateau object at 0x7f149f850650>, <keras.callbacks.EarlyStopping object at 0x7f149f850810>, <keras.callbacks.CSVLogger object at 0x7f149f877c50>]

Steps per epoch: 633
Validation steps: 0

Starting training...

Epoch 1/1000
 - 101s - loss: 0.4526 - acc: 0.8086

Epoch 00001: loss improved from inf to 0.45259, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 2/1000
 - 95s - loss: 0.3821 - acc: 0.8303

Epoch 00002: loss improved from 0.45259 to 0.38210, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 3/1000
 - 94s - loss: 0.3594 - acc: 0.8357

Epoch 00003: loss improved from 0.38210 to 0.35938, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 4/1000
 - 92s - loss: 0.3468 - acc: 0.8401

Epoch 00004: loss improved from 0.35938 to 0.34681, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 5/1000
 - 94s - loss: 0.3276 - acc: 0.8565

Epoch 00005: loss improved from 0.34681 to 0.32760, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 6/1000
 - 96s - loss: 0.3098 - acc: 0.8654

Epoch 00006: loss improved from 0.32760 to 0.30984, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 7/1000
 - 94s - loss: 0.2931 - acc: 0.8740

Epoch 00007: loss improved from 0.30984 to 0.29306, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 8/1000
 - 94s - loss: 0.2738 - acc: 0.8841

Epoch 00008: loss improved from 0.29306 to 0.27379, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 9/1000
 - 97s - loss: 0.2584 - acc: 0.8929

Epoch 00009: loss improved from 0.27379 to 0.25844, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 10/1000
 - 93s - loss: 0.2413 - acc: 0.9003

Epoch 00010: loss improved from 0.25844 to 0.24135, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 11/1000
 - 94s - loss: 0.2279 - acc: 0.9068

Epoch 00011: loss improved from 0.24135 to 0.22790, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 12/1000
 - 93s - loss: 0.2151 - acc: 0.9129

Epoch 00012: loss improved from 0.22790 to 0.21514, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 13/1000
 - 94s - loss: 0.2071 - acc: 0.9159

Epoch 00013: loss improved from 0.21514 to 0.20708, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 14/1000
 - 95s - loss: 0.1994 - acc: 0.9197

Epoch 00014: loss improved from 0.20708 to 0.19940, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 15/1000
 - 97s - loss: 0.1942 - acc: 0.9224

Epoch 00015: loss improved from 0.19940 to 0.19424, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 16/1000
 - 95s - loss: 0.1800 - acc: 0.9280

Epoch 00016: loss improved from 0.19424 to 0.17998, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 17/1000
 - 95s - loss: 0.1741 - acc: 0.9304

Epoch 00017: loss improved from 0.17998 to 0.17413, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 18/1000
 - 94s - loss: 0.1649 - acc: 0.9348

Epoch 00018: loss improved from 0.17413 to 0.16491, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 19/1000
 - 96s - loss: 0.1558 - acc: 0.9384

Epoch 00019: loss improved from 0.16491 to 0.15577, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 20/1000
 - 94s - loss: 0.1476 - acc: 0.9423

Epoch 00020: loss improved from 0.15577 to 0.14758, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 21/1000
 - 94s - loss: 0.1421 - acc: 0.9447

Epoch 00021: loss improved from 0.14758 to 0.14208, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 22/1000
 - 96s - loss: 0.1296 - acc: 0.9496

Epoch 00022: loss improved from 0.14208 to 0.12965, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 23/1000
 - 95s - loss: 0.1203 - acc: 0.9536

Epoch 00023: loss improved from 0.12965 to 0.12032, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 24/1000
 - 97s - loss: 0.1136 - acc: 0.9562

Epoch 00024: loss improved from 0.12032 to 0.11357, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 25/1000
 - 94s - loss: 0.1101 - acc: 0.9577

Epoch 00025: loss improved from 0.11357 to 0.11008, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 26/1000
 - 98s - loss: 0.1025 - acc: 0.9607

Epoch 00026: loss improved from 0.11008 to 0.10250, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 27/1000
 - 94s - loss: 0.0980 - acc: 0.9627

Epoch 00027: loss improved from 0.10250 to 0.09799, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 28/1000
 - 90s - loss: 0.0935 - acc: 0.9646

Epoch 00028: loss improved from 0.09799 to 0.09352, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 29/1000
 - 95s - loss: 0.0890 - acc: 0.9662

Epoch 00029: loss improved from 0.09352 to 0.08902, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 30/1000
 - 97s - loss: 0.0822 - acc: 0.9689

Epoch 00030: loss improved from 0.08902 to 0.08218, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 31/1000
 - 95s - loss: 0.0773 - acc: 0.9707

Epoch 00031: loss improved from 0.08218 to 0.07729, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 32/1000
 - 97s - loss: 0.0739 - acc: 0.9720

Epoch 00032: loss improved from 0.07729 to 0.07387, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 33/1000
 - 93s - loss: 0.0712 - acc: 0.9731

Epoch 00033: loss improved from 0.07387 to 0.07124, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 34/1000
 - 95s - loss: 0.0662 - acc: 0.9751

Epoch 00034: loss improved from 0.07124 to 0.06617, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 35/1000
 - 94s - loss: 0.0653 - acc: 0.9756

Epoch 00035: loss improved from 0.06617 to 0.06533, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 36/1000
 - 95s - loss: 0.0662 - acc: 0.9754

Epoch 00036: loss did not improve from 0.06533
Epoch 37/1000
 - 95s - loss: 0.0583 - acc: 0.9780

Epoch 00037: loss improved from 0.06533 to 0.05828, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 38/1000
 - 95s - loss: 0.0555 - acc: 0.9790

Epoch 00038: loss improved from 0.05828 to 0.05553, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 39/1000
 - 94s - loss: 0.0520 - acc: 0.9805

Epoch 00039: loss improved from 0.05553 to 0.05199, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 40/1000
 - 94s - loss: 0.0504 - acc: 0.9811

Epoch 00040: loss improved from 0.05199 to 0.05039, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 41/1000
 - 96s - loss: 0.0484 - acc: 0.9819

Epoch 00041: loss improved from 0.05039 to 0.04837, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 42/1000
 - 96s - loss: 0.0472 - acc: 0.9821

Epoch 00042: loss improved from 0.04837 to 0.04724, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 43/1000
 - 93s - loss: 0.0463 - acc: 0.9827

Epoch 00043: loss improved from 0.04724 to 0.04625, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 44/1000
 - 96s - loss: 0.0458 - acc: 0.9828

Epoch 00044: loss improved from 0.04625 to 0.04581, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 45/1000
 - 94s - loss: 0.0428 - acc: 0.9840

Epoch 00045: loss improved from 0.04581 to 0.04277, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 46/1000
 - 96s - loss: 0.0382 - acc: 0.9855

Epoch 00046: loss improved from 0.04277 to 0.03824, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 47/1000
 - 96s - loss: 0.0382 - acc: 0.9858

Epoch 00047: loss improved from 0.03824 to 0.03820, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 48/1000
 - 94s - loss: 0.0376 - acc: 0.9860

Epoch 00048: loss improved from 0.03820 to 0.03759, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 49/1000
 - 97s - loss: 0.0366 - acc: 0.9863

Epoch 00049: loss improved from 0.03759 to 0.03660, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 50/1000
 - 100s - loss: 0.0347 - acc: 0.9870

Epoch 00050: loss improved from 0.03660 to 0.03466, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 51/1000
 - 94s - loss: 0.0357 - acc: 0.9867

Epoch 00051: loss did not improve from 0.03466
Epoch 52/1000
 - 96s - loss: 0.0311 - acc: 0.9882

Epoch 00052: loss improved from 0.03466 to 0.03113, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 53/1000
 - 98s - loss: 0.0296 - acc: 0.9888

Epoch 00053: loss improved from 0.03113 to 0.02961, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 54/1000
 - 98s - loss: 0.0325 - acc: 0.9879

Epoch 00054: loss did not improve from 0.02961
Epoch 55/1000
 - 97s - loss: 0.0306 - acc: 0.9886

Epoch 00055: loss did not improve from 0.02961
Epoch 56/1000
 - 96s - loss: 0.0274 - acc: 0.9895

Epoch 00056: loss improved from 0.02961 to 0.02739, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 57/1000
 - 94s - loss: 0.0295 - acc: 0.9890

Epoch 00057: loss did not improve from 0.02739
Epoch 58/1000
 - 94s - loss: 0.0269 - acc: 0.9898

Epoch 00058: loss improved from 0.02739 to 0.02685, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 59/1000
 - 95s - loss: 0.0275 - acc: 0.9896

Epoch 00059: loss did not improve from 0.02685
Epoch 60/1000
 - 94s - loss: 0.0268 - acc: 0.9901

Epoch 00060: loss improved from 0.02685 to 0.02678, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 61/1000
 - 93s - loss: 0.0248 - acc: 0.9906

Epoch 00061: loss improved from 0.02678 to 0.02485, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 62/1000
 - 92s - loss: 0.0231 - acc: 0.9913

Epoch 00062: loss improved from 0.02485 to 0.02314, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 63/1000
 - 97s - loss: 0.0221 - acc: 0.9916

Epoch 00063: loss improved from 0.02314 to 0.02210, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 64/1000
 - 95s - loss: 0.0207 - acc: 0.9920

Epoch 00064: loss improved from 0.02210 to 0.02072, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 65/1000
 - 93s - loss: 0.0208 - acc: 0.9919

Epoch 00065: loss did not improve from 0.02072
Epoch 66/1000
 - 95s - loss: 0.0215 - acc: 0.9918

Epoch 00066: loss did not improve from 0.02072
Epoch 67/1000
 - 91s - loss: 0.0202 - acc: 0.9923

Epoch 00067: loss improved from 0.02072 to 0.02019, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 68/1000
 - 95s - loss: 0.0211 - acc: 0.9919

Epoch 00068: loss did not improve from 0.02019
Epoch 69/1000
 - 94s - loss: 0.0213 - acc: 0.9919

Epoch 00069: loss did not improve from 0.02019
Epoch 70/1000
 - 95s - loss: 0.0187 - acc: 0.9928

Epoch 00070: loss improved from 0.02019 to 0.01871, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 71/1000
 - 94s - loss: 0.0213 - acc: 0.9921

Epoch 00071: loss did not improve from 0.01871
Epoch 72/1000
 - 99s - loss: 0.0212 - acc: 0.9920

Epoch 00072: loss did not improve from 0.01871
Epoch 73/1000
 - 95s - loss: 0.0164 - acc: 0.9937

Epoch 00073: loss improved from 0.01871 to 0.01638, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 74/1000
 - 95s - loss: 0.0160 - acc: 0.9938

Epoch 00074: loss improved from 0.01638 to 0.01603, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 75/1000
 - 99s - loss: 0.0156 - acc: 0.9939

Epoch 00075: loss improved from 0.01603 to 0.01561, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 76/1000
 - 93s - loss: 0.0180 - acc: 0.9931

Epoch 00076: loss did not improve from 0.01561
Epoch 77/1000
 - 96s - loss: 0.0159 - acc: 0.9939

Epoch 00077: loss did not improve from 0.01561
Epoch 78/1000
 - 94s - loss: 0.0162 - acc: 0.9938

Epoch 00078: loss did not improve from 0.01561
Epoch 79/1000
 - 97s - loss: 0.0196 - acc: 0.9926

Epoch 00079: loss did not improve from 0.01561

Epoch 00079: ReduceLROnPlateau reducing learning rate to 4.99999987369e-05.
Epoch 80/1000
 - 96s - loss: 0.0126 - acc: 0.9950

Epoch 00080: loss improved from 0.01561 to 0.01263, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 81/1000
 - 93s - loss: 0.0116 - acc: 0.9954

Epoch 00081: loss improved from 0.01263 to 0.01158, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 82/1000
 - 94s - loss: 0.0107 - acc: 0.9957

Epoch 00082: loss improved from 0.01158 to 0.01070, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 83/1000
 - 96s - loss: 0.0110 - acc: 0.9957

Epoch 00083: loss did not improve from 0.01070
Epoch 84/1000
 - 96s - loss: 0.0105 - acc: 0.9958

Epoch 00084: loss improved from 0.01070 to 0.01051, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 85/1000
 - 95s - loss: 0.0114 - acc: 0.9956

Epoch 00085: loss did not improve from 0.01051
Epoch 86/1000
 - 96s - loss: 0.0099 - acc: 0.9961

Epoch 00086: loss improved from 0.01051 to 0.00994, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 87/1000
 - 95s - loss: 0.0102 - acc: 0.9960

Epoch 00087: loss did not improve from 0.00994
Epoch 88/1000
 - 95s - loss: 0.0105 - acc: 0.9959

Epoch 00088: loss did not improve from 0.00994
Epoch 89/1000
 - 92s - loss: 0.0092 - acc: 0.9963

Epoch 00089: loss improved from 0.00994 to 0.00923, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 90/1000
 - 96s - loss: 0.0090 - acc: 0.9964

Epoch 00090: loss improved from 0.00923 to 0.00904, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 91/1000
 - 100s - loss: 0.0089 - acc: 0.9964

Epoch 00091: loss improved from 0.00904 to 0.00888, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 92/1000
 - 96s - loss: 0.0086 - acc: 0.9966

Epoch 00092: loss improved from 0.00888 to 0.00856, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 93/1000
 - 95s - loss: 0.0101 - acc: 0.9961

Epoch 00093: loss did not improve from 0.00856
Epoch 94/1000
 - 95s - loss: 0.0080 - acc: 0.9968

Epoch 00094: loss improved from 0.00856 to 0.00804, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 95/1000
 - 94s - loss: 0.0084 - acc: 0.9966

Epoch 00095: loss did not improve from 0.00804
Epoch 96/1000
 - 95s - loss: 0.0087 - acc: 0.9966

Epoch 00096: loss did not improve from 0.00804
Epoch 97/1000
 - 97s - loss: 0.0081 - acc: 0.9968

Epoch 00097: loss did not improve from 0.00804
Epoch 98/1000
 - 95s - loss: 0.0084 - acc: 0.9967

Epoch 00098: loss did not improve from 0.00804

Epoch 00098: ReduceLROnPlateau reducing learning rate to 2.49999993684e-05.
Epoch 99/1000
 - 94s - loss: 0.0079 - acc: 0.9968

Epoch 00099: loss improved from 0.00804 to 0.00794, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 100/1000
 - 94s - loss: 0.0068 - acc: 0.9972

Epoch 00100: loss improved from 0.00794 to 0.00683, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 101/1000
 - 98s - loss: 0.0072 - acc: 0.9971

Epoch 00101: loss did not improve from 0.00683
Epoch 102/1000
 - 96s - loss: 0.0068 - acc: 0.9973

Epoch 00102: loss improved from 0.00683 to 0.00681, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 103/1000
 - 97s - loss: 0.0065 - acc: 0.9974

Epoch 00103: loss improved from 0.00681 to 0.00652, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 104/1000
 - 98s - loss: 0.0065 - acc: 0.9974

Epoch 00104: loss did not improve from 0.00652
Epoch 105/1000
 - 94s - loss: 0.0071 - acc: 0.9973

Epoch 00105: loss did not improve from 0.00652
Epoch 106/1000
 - 93s - loss: 0.0071 - acc: 0.9972

Epoch 00106: loss did not improve from 0.00652
Epoch 107/1000
 - 96s - loss: 0.0063 - acc: 0.9975

Epoch 00107: loss improved from 0.00652 to 0.00632, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 108/1000
 - 98s - loss: 0.0062 - acc: 0.9975

Epoch 00108: loss improved from 0.00632 to 0.00624, saving model to weights/innopolis/2019-01-14 08-12-32.hdf5
Epoch 00108: early stopping
Finished training

Date and time: 2019-01-14 11-04-04

