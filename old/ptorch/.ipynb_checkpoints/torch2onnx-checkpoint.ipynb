{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "net = UNet(n_channels=3, n_classes=1)\n",
    "net.load_state_dict(torch.load(\"checkpoints/oldUnet.pth\", map_location='cpu'))\n",
    "net.train(False)\n",
    "\n",
    "# from model.build_BiSeNet import BiSeNet\n",
    "\n",
    "# model = BiSeNet(num_classes=2, context_path='resnet18')\n",
    "\n",
    "# net = U_Net(img_ch=3,output_ch=1)\n",
    "# # net.load_state_dict(torch.load(\"checkpoints/CP99.pth\", map_location='cpu'))\n",
    "# net.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_draft import U_Net\n",
    "\n",
    "net = U_Net(img_ch=3,output_ch=1)\n",
    "net.load_state_dict(torch.load(\"checkpoints/CP99.pth\", map_location='cpu'))\n",
    "net.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input to the model\n",
    "x = torch.randn(1, 3, 256, 256, requires_grad=True)\n",
    "\n",
    "# Export the model\n",
    "torch_out = torch.onnx._export(net,             # model being run\n",
    "                               x,                       # model input (or a tuple for multiple inputs)\n",
    "                               \"oldunet.onnx\", # where to save the model (can be a file or file-like object)\n",
    "                               export_params=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy as np\n",
    "import onnx\n",
    "import caffe2.python.onnx.backend as onnx_caffe2_backend\n",
    "\n",
    "# Load the ONNX ModelProto object. model is a standard Python protobuf object\n",
    "model = onnx.load(\"keke.onnx\")\n",
    "\n",
    "# prepare the caffe2 backend for executing the model this converts the ONNX model into a\n",
    "# Caffe2 NetDef that can execute it. Other ONNX backends, like one for CNTK will be\n",
    "# availiable soon.\n",
    "prepared_backend = onnx_caffe2_backend.prepare(model)\n",
    "\n",
    "# run the model in Caffe2\n",
    "\n",
    "# Construct a map from input names to Tensor data.\n",
    "# The graph of the model itself contains inputs for all weight parameters, after the input image.\n",
    "# Since the weights are already embedded, we just need to pass the input image.\n",
    "# Set the first input.\n",
    "W = {model.graph.input[0].name: x.data.numpy()}\n",
    "\n",
    "# Run the Caffe2 net:\n",
    "c2_out = prepared_backend.run(W)[0]\n",
    "\n",
    "# Verify the numerical correctness upto 3 decimal places\n",
    "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), c2_out, decimal=3)\n",
    "\n",
    "print(\"Exported model has been executed on Caffe2 backend, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.randn(1, 3, 256, 256, requires_grad=True)\n",
    "x2 = torch.randn(1, 3, 256, 256, requires_grad=True)\n",
    "x3 = torch.randn(1, 3, 256, 256, requires_grad=True)\n",
    "x4 = torch.randn(1, 3, 256, 256, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = {model.graph.input[0].name: x1.data.numpy()}\n",
    "c3_out = prepared_backend.run(W)[0]\n",
    "\n",
    "W = {model.graph.input[0].name: x2.data.numpy()}\n",
    "c4_out = prepared_backend.run(W)[0]\n",
    "\n",
    "W = {model.graph.input[0].name: x3.data.numpy()}\n",
    "c5_out = prepared_backend.run(W)[0]\n",
    "\n",
    "W = {model.graph.input[0].name: x4.data.numpy()}\n",
    "c6_out = prepared_backend.run(W)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 320, 1152, dtype=torch.float32, requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, x, \"kek5.onnx\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.onnx import OperatorExportTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Upsample(scale_factor=2)\n",
    "v = torch.randn(1,3,128,128, dtype=torch.float32, requires_grad=False)\n",
    "\n",
    "torch.onnx.export(m, v, \"up.onnx\", verbose=True)\n",
    "\n",
    "# torch_out = torch.onnx._export(m, v, \"up.onnx\", export_params=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"kek5.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caffe2.python.onnx.backend import Caffe2Backend\n",
    "\n",
    "prepared_backend = Caffe2Backend.prepare(onnx_model) #, device='CUDA:0'\n",
    "W = {onnx_model.graph.input[0].name: x.cpu().data.numpy()}\n",
    "c2_out = prepared_backend.run(W)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(torch_out.data.cpu().numpy(), c2_out, decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c2_out.shape\n",
    "del(prepared_backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# for var, obj in locals().items():\n",
    "#     print(var, sys.getsizeof(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.swapaxes(c2_out[0], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(c2_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(c2_out[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_out = c2_out > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "model = onnx.load(\"kek.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = Variable(torch.randn(1, 3, 320, 1152))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, dummy_input, \"alexnet.onnx\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"kek.onnx\")\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import torch\n",
    "from caffe2.python.onnx.backend import Caffe2Backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "model = onnx.load(\"oldunet.onnx\")\n",
    "\n",
    "prepared_backend = Caffe2Backend.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 256, 256, requires_grad=False)\n",
    "W = {model.graph.input[0].name: x.cpu().data.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_out = prepared_backend.run(W)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 512, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c2_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"/home/kenny/Desktop/lanes-segmentation/data/images/um/um_000000.png\"\n",
    "img = plt.imread(file, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_img(ids, directory, suffix):\n",
    "    for iid in ids:\n",
    "        img = np.array(Image.open(directory + iid + suffix))\n",
    "        yield img[:320,:1152]\n",
    "        \n",
    "# In[257]:\n",
    "def hwc_to_chw(img):\n",
    "    return np.transpose(img, axes=[2, 0, 1])\n",
    "\n",
    "# In[258]:\n",
    "def normalize(x):\n",
    "    return np.float32(x/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(Image.open(file))\n",
    "x = x[:320,:1152]\n",
    "x = hwc_to_chw(x)\n",
    "x = normalize(x)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(\"kek6.onnx\")\n",
    "\n",
    "prepared_backend = Caffe2Backend.prepare(model)\n",
    "W = {model.graph.input[0].name: x.cpu().data.numpy()}\n",
    "c2_out = prepared_backend.run(W)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = c2_out[0,0] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
