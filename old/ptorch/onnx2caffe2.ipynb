{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnx_caffe2.backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = onnx.load(\"torchmodel.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_backend = onnx_caffe2.backend.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import caffe2.python.onnx.backend\n",
    "\n",
    "# Prepare the inputs, here we use numpy to generate some random inputs for demo purpose\n",
    "import numpy as np\n",
    "img = np.zeros((1, 3, 320, 1152), dtype=np.float32)\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load('torchmodel.onnx')\n",
    "# Run the ONNX model with Caffe2\n",
    "outputs = caffe2.python.onnx.backend.run_model(model, [img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert-onnx-to-caffe2 assets/squeezenet.onnx --output predict_net.pb --init-net-output init_net.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some standard imports\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import core, net_drawer, net_printer, visualize, workspace, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the mobile nets that we generated above so that caffe2 workspace is properly initialized\n",
    "workspace.RunNetOnce(\"init_net.pb\")\n",
    "workspace.RunNetOnce(predict_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "# Some standard imports\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import core, net_drawer, net_printer, visualize, workspace, utils\n",
    "\n",
    "# run caffe2 inference\n",
    "with open('old_init_net.pb', 'rb') as f:\n",
    "    init_net = f.read()\n",
    "with open('old_predict_net.pb', 'rb') as f:\n",
    "    predict_net = f.read()\n",
    "\n",
    "predictor = workspace.Predictor(init_net, predict_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def load_img(ids, directory, suffix):\n",
    "    for iid in ids:\n",
    "        img = np.array(Image.open(directory + iid + suffix))\n",
    "        yield img[:320,:1152]\n",
    "        \n",
    "# In[257]:\n",
    "def hwc_to_chw(img):\n",
    "    return np.transpose(img, axes=[2, 0, 1])\n",
    "\n",
    "# In[258]:\n",
    "def normalize(x):\n",
    "    return np.float32(x/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "file = \"/home/kenny/Desktop/lanes-segmentation/data/images/um/um_000000.png\"\n",
    "x = np.array(Image.open(file))\n",
    "x = x[:256,:256]\n",
    "x = hwc_to_chw(x)\n",
    "x = normalize(x)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "# x = torch.from_numpy(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 256, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7532529830932617\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "prev_time = time.time()\n",
    "output = predictor.run([x])\n",
    "current_time = time.time()\n",
    "print(current_time-prev_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(output).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.array(output)[0,0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = out > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
